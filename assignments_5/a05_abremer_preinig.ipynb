{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9aea25c1",
      "metadata": {
        "id": "9aea25c1"
      },
      "source": [
        "# [Assignment 5](https://ovgu-ailab.github.io/idl2023/assignment5.html)\n",
        "\n",
        "Collaborative Work from Adrian Bremer and Philipp Reinig"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4126b186",
      "metadata": {
        "id": "4126b186"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4dc6a38e",
      "metadata": {
        "id": "4dc6a38e"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bada4d4e",
      "metadata": {
        "id": "bada4d4e"
      },
      "source": [
        "## Preparing IMDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "80386305",
      "metadata": {
        "id": "80386305"
      },
      "outputs": [],
      "source": [
        "num_words = 20000\n",
        "(train_sequences, train_labels), (test_sequences, test_labels) = tf.keras.datasets.imdb.load_data(num_words=num_words)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7Ef172nfM80",
        "outputId": "8bc8f23f-c996-433d-c2a6-6a030ba2908b"
      },
      "id": "j7Ef172nfM80",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "599876ed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "599876ed",
        "outputId": "c5e2402c-888d-46c7-bb9d-4ba2020b61a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2494\n",
            "238\n"
          ]
        }
      ],
      "source": [
        "sequence_lengths = [len(sequence) for sequence in train_sequences]\n",
        "\n",
        "max_len = max(sequence_lengths)\n",
        "print(max_len)\n",
        "mean_len = int(np.mean(sequence_lengths))\n",
        "print(mean_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ideas for using not the full-length padding scheme**\n",
        "- use the mean length and every other word is _UNKNOWN_\n",
        "  - _truncating_ instead of throwing away since the long sequences are important too because when they are longer the way it is written is different & truncating _the back_ (post) because mostly the first few words are like \"Ehh, this is bad\""
      ],
      "metadata": {
        "id": "0bnYsSd3kZ22"
      },
      "id": "0bnYsSd3kZ22"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "01ecf2cd",
      "metadata": {
        "id": "01ecf2cd"
      },
      "outputs": [],
      "source": [
        "train_sequences_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    train_sequences,\n",
        "    maxlen=mean_len, # max_len\n",
        "    padding=\"pre\",\n",
        "    truncating=\"post\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sequences_padded.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bt0ibtLQDZ7V",
        "outputId": "b1d3a76b-ffb0-4d0a-bfee-cc165bd18fee"
      },
      "id": "Bt0ibtLQDZ7V",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 238)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c359f1ec",
      "metadata": {
        "id": "c359f1ec"
      },
      "outputs": [],
      "source": [
        "# one_hot_sequences_padded = tf.one_hot(indices=train_sequences_padded, depth=num_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem**\n",
        "- the one-hot-vectors are too large so RAM isn't enough\n",
        "\n",
        "**Ideas to fix this**\n",
        "- for storage use integers as vectors because we only need 1 or 0\n",
        "  - here the indices could be used right away\n",
        "- or just use the indices and **construct the one-hot-vectors for each batch**\n",
        "- or encode words of a sequence in one vector but that is not so nice since the word ordering is lost\n",
        "- _Target encoding_ - but that is probably not so easy to adapt to this problem since we need to classify multiple sentences and not single words & we would give away which sentences are important for the classification"
      ],
      "metadata": {
        "id": "MFdqkgWng7_8"
      },
      "id": "MFdqkgWng7_8"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "dfa4700e",
      "metadata": {
        "id": "dfa4700e"
      },
      "outputs": [],
      "source": [
        "train_data = tf.data.Dataset.from_tensor_slices((train_sequences_padded, train_labels)).shuffle(60000).repeat().batch(64)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in train_data:\n",
        "  print(y)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9u9-O9rofZBU",
        "outputId": "e8edb252-617c-4d24-f33a-72b2b205fd12"
      },
      "id": "9u9-O9rofZBU",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[0 1 0 0 1 1 1 1 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 1 0 1 1 0 1 0 1\n",
            " 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 0 1 0 1 1 1 0 0 0 1 1 1], shape=(64,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_lengths = [len(sequence) for sequence in test_sequences]\n",
        "max_len = max(sequence_lengths)\n",
        "\n",
        "test_sequences_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    test_sequences,\n",
        "    maxlen=max_len,\n",
        "    padding=\"pre\",\n",
        "    truncating=\"post\"\n",
        ")\n",
        "test_data = tf.data.Dataset.from_tensor_slices((test_sequences_padded, test_labels)).shuffle(60000)"
      ],
      "metadata": {
        "id": "XWHX26Q3W8eL"
      },
      "id": "XWHX26Q3W8eL",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the RNN"
      ],
      "metadata": {
        "id": "QMFrfclfDoAS"
      },
      "id": "QMFrfclfDoAS"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "19eabfe7",
      "metadata": {
        "id": "19eabfe7"
      },
      "outputs": [],
      "source": [
        "class RNN:\n",
        "  def __init__(self, num_features, num_outputs, num_hidden_units, rand_init_low_high=0.1, activation=tf.nn.sigmoid):\n",
        "    self.nhidden = num_hidden_units\n",
        "    self.activation = activation\n",
        "    self.num_words = num_features\n",
        "    self.Wh = tf.Variable(np.random.uniform(low=-rand_init_low_high, high=rand_init_low_high, size=(num_hidden_units, num_hidden_units)).astype(np.float32))\n",
        "    self.bh = tf.Variable(np.random.uniform(low=-rand_init_low_high, high=rand_init_low_high, size=(num_hidden_units)).astype(np.float32))\n",
        "    self.Wx = tf.Variable(np.random.uniform(low=-rand_init_low_high, high=rand_init_low_high, size=(num_features, num_hidden_units)).astype(np.float32))\n",
        "    self.bx = tf.Variable(np.random.uniform(low=-rand_init_low_high, high=rand_init_low_high, size=(num_hidden_units)).astype(np.float32))\n",
        "    self.Wy = tf.Variable(np.random.uniform(low=-rand_init_low_high, high=rand_init_low_high, size=(num_hidden_units, num_outputs)).astype(np.float32))\n",
        "    self.by = tf.Variable(np.random.uniform(low=-rand_init_low_high, high=rand_init_low_high, size=(num_outputs)).astype(np.float32))\n",
        "\n",
        "  def cell(self, xt, ht_1):\n",
        "    \"\"\"\n",
        "    xt: input x at timestep t\n",
        "    ht_1: output from hidden unit in previous timestep t-1\n",
        "\n",
        "    returns: yt, ht\n",
        "    \"\"\"\n",
        "    xo = tf.matmul(xt, self.Wx) + self.bx\n",
        "    ho = tf.matmul(ht_1, self.Wh) + self.bh\n",
        "    logits = xo + ho\n",
        "    ht = self.activation(logits)\n",
        "    #yt = tf.matmul(self.Wy, ht) + self.by\n",
        "    return ht\n",
        "\n",
        "  def compute_y(self, ht):\n",
        "    return tf.matmul(ht, self.Wy) + self.by\n",
        "\n",
        "  def __call__(self, x):\n",
        "    \"\"\"\n",
        "    batch is of shape (batch_size, timesteps, features)\n",
        "    returns: the logits in the last timestep\n",
        "    \"\"\"\n",
        "    # first hidden activation is 0\n",
        "    ht = tf.Variable(np.zeros(shape=(x.shape[0], self.nhidden)).astype(np.float32))\n",
        "    one_hot_vectors = tf.one_hot(indices=np.swapaxes(x,0,1), depth=self.num_words) # swap batch & timestep to get (timesteps, batch_size, features)\n",
        "    for xt in one_hot_vectors:\n",
        "      # only if not padded\n",
        "      if tf.reduce_max(xt[:,0]) != 0:\n",
        "        ht = self.cell(xt, ht)\n",
        "\n",
        "    return self.compute_y(ht)\n",
        "\n",
        "  def train(self, train_data, num_epochs, steps_per_epoch, optimizer=tf.optimizers.Adam(), loss_fn=tf.losses.CategoricalCrossentropy(from_logits=True)):\n",
        "    variables = [self.Wh, self.Wx, self.Wy, self.bh, self.bx, self.by]\n",
        "    optimizer.build(variables)\n",
        "    for epoch in range(num_epochs):\n",
        "      losses = []\n",
        "      for i,(x,y) in enumerate(train_data):\n",
        "        if i >= steps_per_epoch:\n",
        "          break\n",
        "        with tf.GradientTape() as tape:\n",
        "          logits = self(x)\n",
        "          loss = loss_fn(y, tf.reshape(logits, (x.shape[0],)))\n",
        "\n",
        "        losses.append(loss)\n",
        "\n",
        "        gradients = tape.gradient(loss, variables)\n",
        "        optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "      print(\"Epoch {} done: loss = {}\".format(epoch, np.mean(losses)))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn = RNN(num_words, 1, 100)\n",
        "rnn.train(train_data, 10, 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7NVSiWnWVn3",
        "outputId": "12690a73-d0b6-4b25-91f1-7a00f69b0d58"
      },
      "id": "u7NVSiWnWVn3",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 done: loss = 133.09063720703125\n",
            "Epoch 1 done: loss = 139.35427856445312\n",
            "Epoch 2 done: loss = 135.17076110839844\n",
            "Epoch 3 done: loss = 143.5218505859375\n",
            "Epoch 4 done: loss = 126.86592864990234\n",
            "Epoch 5 done: loss = 149.6897735595703\n",
            "Epoch 6 done: loss = 145.5753173828125\n",
            "Epoch 7 done: loss = 131.01925659179688\n",
            "Epoch 8 done: loss = 103.99049377441406\n",
            "Epoch 9 done: loss = 137.21192932128906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = 0\n",
        "for n, (x,y) in enumerate(test_data.batch(1)):\n",
        "  guess = rnn(x)\n",
        "  if (guess > 0.5 and y == 1) or (guess <= 0.5 and y == 0):\n",
        "    accuracy = (n)/(n+1) * accuracy + 1/(n+1)\n",
        "  else:\n",
        "    accuracy = (n)/(n+1) * accuracy\n",
        "\n",
        "  print(\"\\r\" + str(accuracy), end='', flush=True)\n",
        "\n",
        "\n",
        "# E_n = 1/n * sum(1,n,x_i)\n",
        "#     = 1/n (sum(1,n-1,x_i)+x_n)\n",
        "#     = (n-1)/n * 1/(n-1) * sum(1,n-1,x_i) + x_n/n\n",
        "#     = (n-1)/n * E_n-1 + x_n/n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "_9AuEOLmXi5h",
        "outputId": "7ae02a36-dc72-4e7a-e6db-317ad99ba792"
      },
      "id": "_9AuEOLmXi5h",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.55"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-e68d3750c95f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mguess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mguess\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mguess\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-99abd7724022>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mht\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mone_hot_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# swap batch & timestep to get (timesteps, batch_size, features)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mxt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mone_hot_vectors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m       \u001b[0;31m# only if not padded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m   1139\u001b[0m           \u001b[0marray_ops_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m           \u001b[0marray_ops_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m           array_ops_stack.stack(strides))\n\u001b[0m\u001b[1;32m   1142\u001b[0m       \u001b[0;31m# TODO(mdan): Instead of implicitly casting, it's better to enforce the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m       \u001b[0;31m# same dtypes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0merror_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_traceback_filtering_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36mis_traceback_filtering_enabled\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtf_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'debugging.is_traceback_filtering_enabled'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_traceback_filtering_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m   \"\"\"Check whether traceback filtering is currently enabled.\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations**\n",
        "- the forward step is really slow\n",
        "- therefore training this takes ages\n",
        "  - _**How can you speed this up or is it correct because of the sequential manner of the RNN?**_\n",
        "- _currently_: network is guessing (accuracy of around 50%)\n",
        "\n",
        "**Thoughts about outputs**\n",
        "- having one output means that e.g. 1 is hate speech and 0 is not\n",
        "  - therefore, the relation between them is hate_speech = 1 - friendly\n",
        "- having 2 output units on the other hand means that output unit 1 is for hate and output unit 2 is for friendly\n",
        "  - here they don't necessarly need to add up to 1 since a text may criticise but also emphasises good parts of the movie\n",
        "- HERE: it is easier with one unit because you can directly compare with the given binary labels -> _there is no such intermediate thing as mentioned above_\n"
      ],
      "metadata": {
        "id": "F7WmXeWuq1lP"
      },
      "id": "F7WmXeWuq1lP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Open problems"
      ],
      "metadata": {
        "id": "_HsjRtprseqS"
      },
      "id": "_HsjRtprseqS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**initial state**\n",
        "- in this case there is no need to learn an initial state because each review is independent of the other ones\n",
        "- the initial state would give a tendence if a review is positiv or negative and this is not feasible here\n",
        "\n",
        "**when to pad**\n",
        "- pre-padding would probably be better, because when the sentence ends we generate the output instead of having to feed the current hidden activation through he network\n",
        "\n",
        "**avoid computing padded sequences**\n",
        "- Since we padded with 0, we could check if hot_vector[0] contains a 1\n",
        "- if it contains it, we could skip"
      ],
      "metadata": {
        "id": "eFU0UlZFsi6R"
      },
      "id": "eFU0UlZFsi6R"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use outputs from every timestep"
      ],
      "metadata": {
        "id": "k2ITw5FTxN6Y"
      },
      "id": "k2ITw5FTxN6Y"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hkejM0zZxT2d"
      },
      "id": "hkejM0zZxT2d",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}